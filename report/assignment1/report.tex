\documentclass[journal]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{minted}
\usepackage{booktabs}
\usepackage{color}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{multirow}

\usepackage[binary-units=true]{siunitx}

\newcommand{\scala}[1]{\mintinline{scala}{#1}}

\title{Advanced Algorithms (\texttt{LINGI2266}) \\ Assignment 1: Knapsack problem}
\author{Gilles Peiffer}
\date{October 11, 2019}

\begin{document}

\maketitle

\begin{abstract}
	An analysis of the solution to the knapsack problem which takes into account various dimensions along which to judge algorithms for this problem is given.
	Various heuristics are given, some of which are based on a theoretical understanding of the mathematics behind the knapsack problem, while others are highly-specialized in order to profit from the input formulation as much as possible.
	Some implementation fragments in Scala are also presented.
\end{abstract}

\section{Introduction}
\label{sec:intro}
The goal for this assignment was to solve various instances of the \emph{knapsack problem}, defined as follows:
\[
\begin{array}{rrcl@{\quad}l}
\textnormal{maximize} & \sum_{i \in \{1, \ldots, n\}} x_i v_i &&& \\
\textnormal{such that} & \sum_{i \in \{1, \ldots, n\}} x_i w_i & \le & C &\\
& x_i & \in & \{0, 1\} & \forall i \in \{1, \ldots, n\}
\end{array}
\]

The two main types of algorithms used to solve this class of problems are
\begin{itemize}
	\item \emph{dynamic programming} and
	\item \emph{branch and bound}.
\end{itemize}
Each of these has its own advantages and disadvantages, which usually allow one to make an informed choice as to which algorithm is best-suited for a particular instance of the knapsack problem.

\section{I/O}
In order to be easily tested on INGInious, the input and output for this particular instance have a very specific fixed format.
\subsection{Reading the Input}
The program is given a \scala{String} as input which contains the path to the data file.
This file is opened and read according to the format specified in the problem description on INGInious, and uses Scala code written for this purpose by Pierre Schaus.

\subsection{Output Formatting}
The \scala{toString} method definition is overridden in order to produce output with the correct format.
This requires some internal bookkeeping, explained in slightly more detail in Sections~\ref{sec:dpoutput} (for dynamic programming) and \ref{sec:bnboutput} (for branch and bound).

\section{Dynamic Programming}
Dynamic programming, or DP for short, is an algorithmic technique which uses memoization in order to improve computation time at the cost of memory space.

\subsection{Recurrence Equations}
One has to define an \emph{objective function} \(\mathscr{O}(j, k)\), which, for the knapsack problem, gives the optimal value that can be obtained using items 1 through \(j\) and with a capacity \(k\).
This function can be defined recursively as follows:
\[
\mathscr{O}(j, k) = \left\{
\begin{array}{ll}
\max\big\{ \mathscr{O}(j-1, k), & \multirow{2}{*}{\(\textnormal{if } w_j \le k,\)}\\
\qquad v_j + \mathscr{O}(j-1, k-w_j) \big\}, & \\\\
\mathscr{O}(j-1, k), & \textnormal{otherwise,}\\\\\\
0, & \textnormal{if } j = 0.
\end{array}
\right.
\]
By this definition, the final solution to the problem is \(\mathscr{O}(n, C)\).
\subsection{Implementation}
Turning these equations into Scala is fairly straightforward.
The following is what one could consider the ``core'' of the implementation:
\begin{minted}[fontsize=\scriptsize]{scala}
val cache = collection.mutable.Map.empty[(Int, Int), Int]
val tkn = collection.mutable.Map.empty[(Int, Int), Boolean]
def O(j: Int, k: Int): Int = {
  if (j < 0) 0
  else {
    val (vj, wj) = items(j)
    if (wj > k) {
      tkn.update((j, k), false)
      O_(j-1,k)
    } else {
      if (O_(j-1,k) > vj + O_(j-1,k-wj)) {
        tkn.update((j, k), false)
        O_(j-1,k)
      } else {
        tkn.update((j, k), true)
        vj + O_(j-1,k-wj)
      }
    }
  }
}
def O_(j: Int, k: Int): Int = {
  cache.getOrElseUpdate((j,k), O(j,k))
}
println(O(n-1, c))
\end{minted}
\subsubsection{Recurrence}
The recurrence equation given earlier is implemented in the form of a multitude of nested \scala{if}/\scala{else} branches, and a function call to \scala{O_}, which is explained in Section~\ref{sec:dpmemo}.
One should also note that instead of the solution being \(\mathscr{O}(n, C)\), one must call \scala{O(n-1, C)}; this is explained by the fact that in Scala, array indexing starts at 0, causing a potential off-by-one error that must be kept in mind.
\subsubsection{Memoization}
\label{sec:dpmemo}
The main goal of DP is to speed up computation time by storing values that were already computed--also called \emph{memoization}--and reusing those values whenever applicable.
In the code fragment, \scala{cache} is responsible for this: whenever a value of \scala{O}, the objective function, is needed, the program calls \scala{O_} which serves as an alias for \scala{cache.getOrElseUpdate}.
The latter's name describes what it does quite aptly: informally, it tells the computer to go and check if the value that is needed is already stored in \scala{cache}.
If it is, \scala{O_} simply returns that value; on the other hand, if it was not cached yet, it is computed (using the recursive property of the objective function) and the result is stored in \scala{cache} for future reference.
\subsubsection{Output Formatting}
\label{sec:dpoutput}
The \scala{Map} called \scala{tkn} stores whether the optimal solution for a given \scala{j} and \scala{k} uses the \scala{j}th element.
This is not related to the actual knapsack problem, but is necessary to be able to construct the output according to the specifications.

\subsection{Advantages and Disadvantages}
\subsubsection{Advantages}
DP has several advantages:
\begin{itemize}
	\item The algorithm is very easy to understand and easy to debug.
	\item \emph{For small values of \(C\)}, the algorithm is very fast and can very quickly solve problems which would be nigh impossible with a brute force search.
\end{itemize}
\subsubsection{Disadvantages}
On the other hand, there are some major downsides to the DP algorithm as well:
\begin{itemize}
	\item \emph{For large values of \(C\)}, the algorithm's pseudo-polynomiality makes it unusable.
	A variation based on the value \(V\) is also possible, but the same restrictions apply when \(V\) is large.
	This is for example what caused Instance B to take far too long using DP: for reference, while there are only 56 items to select, the maximum capacity and optimal value are both 104 723 596, meaning neither variation of the algorithm performs adequately.
\end{itemize}
Taking all of this into account, DP makes for a good first try at a solution, and can serve as an easy way to obtain solutions to a real-life problem to see whether other, more complex algorithms are correctly implemented and thought out.
For this assignment, two instances were solved using DP (D and E).

\section{Branch and Bound}
Branch and bound, or BnB for short, is an algorithm which uses upper-bounding and tree search in order to discard parts of a huge binary tree which have been shown not to contain an optimal solution.
More formally, consider the knapsack problem of Section~\ref{sec:intro}.
This problem, in a way, searches for a tuple of binary values which maximizes the objective function.
Consider the search tree formed by the possible value assignments to this tuple.
At the root, all variables are ``free'' to be either 1 or 0, but every time the tree branches in two, the left subtree has a variable set to 1, while the right subtree has that same variable set to 0.
If one has a procedure to efficiently find an upper bound for the subtree rooted at a certain node, the optimal solution can be obtained by first finding a feasible solution, and then trying to find a better one while discarding subtrees with an upper bound lower than or equal to the best known value of the feasible solution.
This way, one can avoid having to explore the entire search tree, whose size grows exponentially with the number of decision variables.

\subsection{Design Choices}
The explanation above is purposely vague, since many design choices still need to be taken based on the specific instance of the problem.
The most important is of the upper-bounding procedure.
While technically not necessary to find a solution, this is required to help discard subtrees faster and thus make the algorithm solve problems much more efficiently.
If the upper-bounding procedure is not sufficiently tight (or takes a long time to compute), branch and bound is not much better than a brute force approach.

\subsubsection{Upper-bounding}
The upper-bounding procedure of choice, which gives great results in the majority of cases, is called \emph{linear relaxation}.
What LR does is, instead of forcing variables to be binary, it allows them to be anywhere in \([0, 1]\).
By then sorting free items (i.e., whose decision variable has not been set yet) by their utility ratio, that is, the ratio between their value and weight, and selecting as many of these items (and potentially, fractions of items) as possible until the capacity constraint is tight, we can guarantee that the optimal objective will be lower than or equal to this upper bound.

To implement this, we do the following (suppose that \scala{selectable} has been \textbf{sorted} already):
\begin{minted}[fontsize=\scriptsize]{scala}
override val upperBound: Double = {
  // Linear relaxation.
  var i: Int = 0
  var ub: Double = obj
  var c: Int = capa
  if (c > 0) {
    while (i < selectable.length
        && c >= weight(selectable(i))) {
      c = c - weight(selectable(i))
      ub = ub + value(selectable(i))
      i += 1
    }
    if (i < selectable.length) {
      val d: Double = c.toDouble / weight(selectable(i))
      ub = ub + value(selectable(i)) * d
    }
  }
  ub
}
\end{minted}
In this code fragment, one can distinguish two main steps:
\begin{enumerate}
	\item first, use all the free variables (those in \scala{selectable}) in order to find the \emph{critical item} which would make the knapsack too full;
	\item add whatever you can of the critical item, maxing out the capacity.
\end{enumerate}

Additionally, though not necessary, the flooring function can be applied to this final result, since one can prove that if the weights and values are integers, then so is the optimal solution.

\subsubsection{Traversal algorithm}
This section mentions the traversal algorithms which can be used to decide which nodes are to be explored first.
Concretely, two options exist, each with their own advantages and disadvantages:
\begin{itemize}
	\item \emph{Best-first search}.
	This traversal looks at the most promising nodes (highest upper bound) first.
	This search strategy can be implemented with a \scala{PQueue}; the code used for this is heavily influenced by the one on the course's BitBucket repository, written by Pierre Schaus.
	The main advantage of this strategy is also its main drawback: it depends heavily on the quality of the upper-bounding procedure in order to be successful.
	Another big drawback is that the user has no control over the number of open nodes which are kept in memory.
	\item \emph{Depth-first search}.
	DFS looks at the deepest, leftmost node first, regardless of the upper bound (as long as exploring the subtree makes sense, i.e. as long as the subtree potentially contains an optimal solution).
	This can be implemented with a \scala{Stack}.
	This strategy, while not being as good in general at finding optimal solutions, does fare much better in the memory department, since memory consumption is proportional to the height of the tree, which is typically linear.
\end{itemize}
In the code, the only change that needs to be made is in the \scala{OpenNodes} implementation.

For this assignment, a best-first search algorithm using linear relaxation for upper bounding was used to solve instances A, C and F, which did either not get solved within the memory and time constraints by the DP algorithm (C) or because BnB was implemented before DP (A and F, where both algorithms arrive at the correct solution).

\subsection{Output formatting}
\label{sec:bnboutput}
When sorting the elements with the goal of being able to apply LR, the initial order gets lost.
This is quite problematic for this particular assignment, since the output format makes use of the initial order.
To get around this problem, one can add the original weight and value vectors to the \scala{KnapsackNode}, using these to identify used items.
The assumption that two items cannot be identical was verified beforehand, meaning this is a correct way for the instances of the assignment to recover the initial ordering.

\subsection{The Peculiar Case of Instance B}
Instance B has the property that all its items have a unit utility ratio.
This means that sorting them does nothing, other than potentially shuffle them (since quicksort is not a stable sort).
Add in the fact that the LR upper bound, while tight, gives little extra information in this case, and one quickly gets a problem which takes a very long time to get solved.

However, seeing as sorting by utility ratio does not change the ordering, and that the upper bound, despite being tight, does not allow best-first search to solve the problem optimally fast enough, an algorithm using DFS based on a \scala{Stack} was implemented, with elements being sorted based on their value (most valuable items being taken first).

This algorithm outperforms the other BnB one (and the DP solver as well) by quite some margin, finding the optimal solution in a matter of seconds (in fact, it happens to go down the ``optimal'' path almost immediately due to the order in which variables are examined).

\section{Conclusion}
The knapsack problem is one of the most important problems in combinatorial optimization, and DP and BnB are only some of the many possible ways to solve instances of it.
Thanks to this assignment, we learnt that in some cases, it is very hard to predict which algorithm is best-suited to a given instance.

Implementing the various algorithms helped to better understand why and how they work, while playing around with them on various instances helped to identify their strengths and shortcomings.
\end{document}